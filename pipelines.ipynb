{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get into the magic of Pipelines\n",
    "\n",
    "# Pipelines\n",
    "    # Bundles preprocesses into a single step to keep code organized and clean\n",
    "\n",
    "# Benefits of Pipelines:\n",
    "    # Cleaner Code: Won't need to keep track of data each step of the way\n",
    "    # Fewer Bugs: Fewer opportunities to create mis-steps in your code\n",
    "    # Easier to Productionize: Easier to transition a model from dev to prod\n",
    "    # More Options for Model Testing: Yayyy\n",
    "    \n",
    "    # Let's take a look at what we mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting things up\n",
    "import pandas as pd\n",
    "\n",
    "# Import our PDP plot and Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import our dataset\n",
    "df = pd.read_csv('./datasets/melb_data.csv')\n",
    "\n",
    "use_columns = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "\n",
    "X = df[use_columns]\n",
    "y = df.Price\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewquinn/.local/share/virtualenvs/data-science-learning-e1DZx5Tr/lib/python3.7/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Now let's use Pipelines to define and fit our model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# As you can see, we setup our Imputer and RandomForest using a Pipeline\n",
    "my_pipeline = make_pipeline(Imputer(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit using out Pipeline\n",
    "# Before pipeline:\n",
    "    # IMPUTE\n",
    "        # my_imputer = Imputer()\n",
    "    # DEFINE MODEL\n",
    "        # my_model = RandomForestRegressor()\n",
    "    # IMPUTE\n",
    "        #imputed_train_X = my_imputer.fit_transform(train_X)\n",
    "        #imputed_test_X = my_imputer.transform(test_X)\n",
    "    # FIT\n",
    "        # my_model.fit(imputed_train_X, train_y)\n",
    "\n",
    "# After pipeline:\n",
    "my_pipeline.fit(train_X, train_y)\n",
    "predict = my_pipeline.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More about Pipelines and scikit-learn objects (transformers or models)\n",
    "    # Transformers: Pre-processing before modeling (Imputer)\n",
    "    # Models: Used to make predictions\n",
    "# Pipelines must start with a transformer and end with a model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
